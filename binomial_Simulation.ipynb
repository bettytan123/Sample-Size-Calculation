{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bettytan123/Sample-Size-Calculation/blob/main/binomial_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "969740c6",
      "metadata": {
        "id": "969740c6"
      },
      "outputs": [],
      "source": [
        "############################################\n",
        "## This script will simulate data from known statistical distirbutions; then estimate GAN and sample from it\n",
        "##\n",
        "## Authors: Betty and Chris\n",
        "## Date: February 2023\n",
        "############################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sdv --quiet\n",
        "! pip install --upgrade scipy --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqfh0fn2Lf9T",
        "outputId": "9113ba8a-5450-42a1-a555-1743430b7b17"
      },
      "id": "Dqfh0fn2Lf9T",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 KB\u001b[0m \u001b[31m529.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.0/140.0 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "718ec3e3",
      "metadata": {
        "id": "718ec3e3"
      },
      "outputs": [],
      "source": [
        "########################\n",
        "## Import dependency packages\n",
        "########################\n",
        "\n",
        "## Import SDV for GANs and sampling mechanisms, etc.\n",
        "from sdv.tabular import CTGAN\n",
        "\n",
        "## Import pandas for data structures\n",
        "import pandas as pd\n",
        "\n",
        "## Import numpy for numerical computing\n",
        "import numpy as np\n",
        "\n",
        "## Import scipy for statistical distirbution function \n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "## For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## For timing\n",
        "from time import time\n",
        "\n",
        "## Random Numbers\n",
        "import random\n",
        "\n",
        "# For progress bars\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "# Do not display warnings (bad practice)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#able to faster the process \n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "58a0cdfe",
      "metadata": {
        "id": "58a0cdfe"
      },
      "outputs": [],
      "source": [
        "## Set seed \n",
        "random.seed(12345)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "905dff11",
      "metadata": {
        "id": "905dff11"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "781ef186",
      "metadata": {
        "id": "781ef186"
      },
      "outputs": [],
      "source": [
        "#####################################\n",
        "##\n",
        "## Sample Size for Precision of a binanry Random Variable --- by Mathemtical Theory\n",
        "##\n",
        "#####################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "674da3b3",
      "metadata": {
        "id": "674da3b3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c527bb4e",
      "metadata": {
        "id": "c527bb4e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import scipy\n",
        "def samp_size_bin_ci(alpha, proportion, width):\n",
        "    Number = (4 * (scipy.stats.norm.ppf(q=alpha/2, loc=0, scale=1)**2) * proportion*(1-proportion) / (width**2))\n",
        "    return Number\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "45ffc8c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ffc8c0",
        "outputId": "6ddf48c0-49da-48a0-9a52-517f91538976"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "245.8533645244241"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "samp_size_bin_ci(alpha=0.05, proportion=0.2, width=0.1) ##245.8534"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SSl56uxKQiAO"
      },
      "id": "SSl56uxKQiAO",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Size for Precision of a binaral Random Variable --- by numerical simulation\n"
      ],
      "metadata": {
        "id": "DRJRtIJtQkIL"
      },
      "id": "DRJRtIJtQkIL"
    },
    {
      "cell_type": "code",
      "source": [
        "alpha= 0.05\n",
        "n = int(np.ceil(samp_size_bin_ci(alpha=0.05, proportion=0.2, width=0.1)))\n",
        "k = 100 #he number of successes.\n",
        "n_size =1000\n",
        "p = k/n\n",
        "## Generate random data\n",
        "x = np.random.binomial(n= n, p = p, size = n_size)\n",
        "## Analyze generated/simulated data\n",
        "res = scipy.stats.binomtest(k=k, n =n, p=p, alternative='two-sided')\n"
      ],
      "metadata": {
        "id": "-x4uudUlklpI"
      },
      "id": "-x4uudUlklpI",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpwKrv5PkluA",
        "outputId": "87ee5ff4-a1a7-4105-b4d3-dc5a6a7d6f37"
      },
      "id": "JpwKrv5PkluA",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BinomTestResult(k=100, n=246, alternative='two-sided', statistic=0.4065040650406504, pvalue=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n, p = 10, .5  # number of trials, probability of each trial\n",
        "# s = np.random.binomial(n, p, 1000)\n",
        "# # np.random.binomial(n= 10, p = 0.5, size=2 )"
      ],
      "metadata": {
        "id": "jyUAuKmFklx6"
      },
      "id": "jyUAuKmFklx6",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_ci_samp_size(n, p ,size):\n",
        "    ## Generate random data\n",
        "    x = np.random.binomial(n= n, p = p, size= n_size)\n",
        "    ## Analyze generated/simulated data\n",
        "    res = scipy.stats.binomtest(k=k, n =n, p=p, alternative='two-sided')\n",
        "    \n",
        "    ## Extract the estimate and CI\n",
        "    p_ll, p_ul = res.proportion_ci(confidence_level=0.95)\n",
        "    p_hat = np.mean(x)\n",
        "    \n",
        "    # Return the estimate and the CI to the user\n",
        "    # [] make it a list instead of scalar\n",
        "    out = pd.DataFrame({'mean': [p_hat],\n",
        "                        'll95_mean': [p_ll],\n",
        "                        'ul95_mean': [p_ul]})\n",
        "    \n",
        "    return(out)\n"
      ],
      "metadata": {
        "id": "e4XqnriEkl1h"
      },
      "id": "e4XqnriEkl1h",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Replicate above function number of simulation replicate times\n",
        "\n",
        "# parameter available  \n",
        "n = int(np.ceil(samp_size_bin_ci(alpha=0.05, proportion=0.2, width=0.1)))\n",
        "\n",
        "k = 100 \n",
        "p = k/n\n",
        "## Number simulation replicates\n",
        "n_rep = 10000\n",
        "\n",
        "## Simulate n_rep copies of sample size trials\n",
        "sim_out = []\n",
        "\n",
        "#Record start time\n",
        "t0 = time()\n",
        "\n",
        "## Loop over number simulation replicates, storing results in list\n",
        "for i in range(0, n_rep):\n",
        "    sim_out.append(bin_ci_samp_size(n, p, size= n_size))\n",
        "\n",
        "#Record end time\n",
        "t1 = time()\n",
        "\n",
        "#Calculate runtime\n",
        "runtime = t1 - t0\n",
        "print(f'runtime is {runtime}')\n",
        "\n",
        "### Aggregate results into dataframe\n",
        "sim_df = pd.concat(sim_out)\n",
        "\n",
        "#Calculate means of each column in the array #axis means column mean \n",
        "sim_means = np.mean(sim_df, axis=0)\n",
        "print(f'sim_means is {sim_means}')\n",
        "\n",
        "#Calculate the width of the confidence interval\n",
        "ci_width = sim_means[2] - sim_means[1]\n",
        "print(f'ci_width is {ci_width}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-P9WdqutREx",
        "outputId": "7d5c466e-1ec9-40c8-da11-ecd2270505c4"
      },
      "id": "6-P9WdqutREx",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runtime is 64.52251148223877\n",
            "sim_means is mean         100.002039\n",
            "ll95_mean      0.344552\n",
            "ul95_mean      0.470738\n",
            "dtype: float64\n",
            "ci_width is 0.12618563749466377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "20vuRG9ftRHo"
      },
      "id": "20vuRG9ftRHo",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uoKVeFSwtRKZ"
      },
      "id": "uoKVeFSwtRKZ",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Size for Precision of a Continuous Normal Random Variable --- by GAN (generative adversarial network) just fitting once (i.e., one input"
      ],
      "metadata": {
        "id": "3RcLe5PHkgQp"
      },
      "id": "3RcLe5PHkgQp"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4432dd1e",
      "metadata": {
        "id": "4432dd1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2aa9901-b5d2-41c9-8d89-d2a537763218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss G:  0.0578,Loss D:  0.0014\n",
            "Epoch 2, Loss G:  0.0579,Loss D:  0.0143\n",
            "Epoch 3, Loss G:  0.0607,Loss D:  0.0121\n",
            "Epoch 4, Loss G:  0.0585,Loss D:  0.0135\n",
            "Epoch 5, Loss G:  0.0562,Loss D:  0.0206\n",
            "Epoch 6, Loss G:  0.0585,Loss D:  0.0194\n",
            "Epoch 7, Loss G:  0.0587,Loss D:  0.0232\n",
            "Epoch 8, Loss G:  0.0553,Loss D:  0.0300\n",
            "Epoch 9, Loss G:  0.0508,Loss D:  0.0367\n",
            "Epoch 10, Loss G:  0.0474,Loss D:  0.0351\n",
            "Epoch 11, Loss G:  0.0455,Loss D:  0.0481\n",
            "Epoch 12, Loss G:  0.0413,Loss D:  0.0469\n",
            "Epoch 13, Loss G:  0.0434,Loss D:  0.0462\n",
            "Epoch 14, Loss G:  0.0413,Loss D:  0.0620\n",
            "Epoch 15, Loss G:  0.0355,Loss D:  0.0597\n",
            "Epoch 16, Loss G:  0.0389,Loss D:  0.0668\n",
            "Epoch 17, Loss G:  0.0395,Loss D:  0.0733\n",
            "Epoch 18, Loss G:  0.0383,Loss D:  0.0850\n",
            "Epoch 19, Loss G:  0.0335,Loss D:  0.0808\n",
            "Epoch 20, Loss G:  0.0325,Loss D:  0.0893\n",
            "Epoch 21, Loss G:  0.0468,Loss D:  0.0883\n",
            "Epoch 22, Loss G:  0.0398,Loss D:  0.0881\n",
            "Epoch 23, Loss G:  0.0552,Loss D:  0.0820\n",
            "Epoch 24, Loss G:  0.0576,Loss D:  0.0929\n",
            "Epoch 25, Loss G:  0.0591,Loss D:  0.0751\n",
            "Epoch 26, Loss G:  0.0642,Loss D:  0.0759\n",
            "Epoch 27, Loss G:  0.0793,Loss D:  0.0696\n",
            "Epoch 28, Loss G:  0.0884,Loss D:  0.0543\n",
            "Epoch 29, Loss G:  0.1082,Loss D:  0.0512\n",
            "Epoch 30, Loss G:  0.1192,Loss D:  0.0298\n",
            "Epoch 31, Loss G:  0.1422,Loss D:  0.0306\n",
            "Epoch 32, Loss G:  0.1624,Loss D:  0.0078\n",
            "Epoch 33, Loss G:  0.1904,Loss D: -0.0054\n",
            "Epoch 34, Loss G:  0.1735,Loss D: -0.0214\n",
            "Epoch 35, Loss G:  0.2157,Loss D: -0.0319\n",
            "Epoch 36, Loss G:  0.2155,Loss D: -0.0818\n",
            "Epoch 37, Loss G:  0.2385,Loss D: -0.0586\n",
            "Epoch 38, Loss G:  0.2412,Loss D: -0.0895\n",
            "Epoch 39, Loss G:  0.2652,Loss D: -0.0765\n",
            "Epoch 40, Loss G:  0.2620,Loss D: -0.0819\n",
            "Epoch 41, Loss G:  0.2608,Loss D: -0.0782\n",
            "Epoch 42, Loss G:  0.2467,Loss D: -0.0973\n",
            "Epoch 43, Loss G:  0.2432,Loss D: -0.0916\n",
            "Epoch 44, Loss G:  0.2555,Loss D: -0.0845\n",
            "Epoch 45, Loss G:  0.2458,Loss D: -0.0857\n",
            "Epoch 46, Loss G:  0.2184,Loss D: -0.0856\n",
            "Epoch 47, Loss G:  0.2074,Loss D: -0.0722\n",
            "Epoch 48, Loss G:  0.2281,Loss D: -0.0414\n",
            "Epoch 49, Loss G:  0.2027,Loss D: -0.0550\n",
            "Epoch 50, Loss G:  0.1877,Loss D: -0.0379\n",
            "Epoch 51, Loss G:  0.1896,Loss D: -0.0203\n",
            "Epoch 52, Loss G:  0.1706,Loss D: -0.0688\n",
            "Epoch 53, Loss G:  0.1914,Loss D: -0.0274\n",
            "Epoch 54, Loss G:  0.2077,Loss D: -0.0776\n",
            "Epoch 55, Loss G:  0.1888,Loss D: -0.0845\n",
            "Epoch 56, Loss G:  0.2195,Loss D: -0.0919\n",
            "Epoch 57, Loss G:  0.2255,Loss D: -0.1201\n",
            "Epoch 58, Loss G:  0.2284,Loss D: -0.1359\n",
            "Epoch 59, Loss G:  0.2515,Loss D: -0.0838\n",
            "Epoch 60, Loss G:  0.2686,Loss D: -0.1405\n",
            "Epoch 61, Loss G:  0.2839,Loss D: -0.1549\n",
            "Epoch 62, Loss G:  0.3021,Loss D: -0.1694\n",
            "Epoch 63, Loss G:  0.3155,Loss D: -0.2076\n",
            "Epoch 64, Loss G:  0.3269,Loss D: -0.2015\n",
            "Epoch 65, Loss G:  0.3239,Loss D: -0.1919\n",
            "Epoch 66, Loss G:  0.3198,Loss D: -0.1770\n",
            "Epoch 67, Loss G:  0.2892,Loss D: -0.1972\n",
            "Epoch 68, Loss G:  0.2790,Loss D: -0.2005\n",
            "Epoch 69, Loss G:  0.2918,Loss D: -0.1869\n",
            "Epoch 70, Loss G:  0.2277,Loss D: -0.1681\n",
            "Epoch 71, Loss G:  0.2050,Loss D: -0.1767\n",
            "Epoch 72, Loss G:  0.1418,Loss D: -0.1272\n",
            "Epoch 73, Loss G:  0.1052,Loss D: -0.1012\n",
            "Epoch 74, Loss G:  0.0992,Loss D: -0.0533\n",
            "Epoch 75, Loss G:  0.0378,Loss D: -0.0210\n",
            "Epoch 76, Loss G:  0.0387,Loss D: -0.0235\n",
            "Epoch 77, Loss G:  0.0139,Loss D: -0.0181\n",
            "Epoch 78, Loss G: -0.0360,Loss D: -0.0074\n",
            "Epoch 79, Loss G: -0.0349,Loss D:  0.0198\n",
            "Epoch 80, Loss G: -0.0334,Loss D:  0.0578\n",
            "Epoch 81, Loss G: -0.0576,Loss D:  0.0203\n",
            "Epoch 82, Loss G: -0.0541,Loss D:  0.0438\n",
            "Epoch 83, Loss G: -0.0605,Loss D:  0.0331\n",
            "Epoch 84, Loss G: -0.0532,Loss D:  0.0330\n",
            "Epoch 85, Loss G: -0.0681,Loss D:  0.0047\n",
            "Epoch 86, Loss G: -0.0381,Loss D:  0.0264\n",
            "Epoch 87, Loss G: -0.0594,Loss D:  0.0067\n",
            "Epoch 88, Loss G: -0.0762,Loss D:  0.0121\n",
            "Epoch 89, Loss G: -0.0604,Loss D: -0.0005\n",
            "Epoch 90, Loss G: -0.0702,Loss D:  0.0037\n",
            "Epoch 91, Loss G: -0.0829,Loss D: -0.0069\n",
            "Epoch 92, Loss G: -0.0839,Loss D:  0.0161\n",
            "Epoch 93, Loss G: -0.1108,Loss D:  0.0305\n",
            "Epoch 94, Loss G: -0.1235,Loss D:  0.0437\n",
            "Epoch 95, Loss G: -0.1457,Loss D:  0.0720\n",
            "Epoch 96, Loss G: -0.1505,Loss D:  0.0543\n",
            "Epoch 97, Loss G: -0.1569,Loss D:  0.0800\n",
            "Epoch 98, Loss G: -0.1512,Loss D:  0.0922\n",
            "Epoch 99, Loss G: -0.1416,Loss D:  0.0895\n",
            "Epoch 100, Loss G: -0.1542,Loss D:  0.1097\n",
            "Epoch 101, Loss G: -0.1458,Loss D:  0.0691\n",
            "Epoch 102, Loss G: -0.1182,Loss D:  0.0591\n",
            "Epoch 103, Loss G: -0.1057,Loss D:  0.0464\n",
            "Epoch 104, Loss G: -0.0685,Loss D:  0.0119\n",
            "Epoch 105, Loss G: -0.0545,Loss D: -0.0287\n",
            "Epoch 106, Loss G: -0.0272,Loss D: -0.0375\n",
            "Epoch 107, Loss G: -0.0231,Loss D: -0.0378\n",
            "Epoch 108, Loss G: -0.0291,Loss D: -0.0438\n",
            "Epoch 109, Loss G: -0.0216,Loss D: -0.0304\n",
            "Epoch 110, Loss G: -0.0230,Loss D: -0.0276\n",
            "Epoch 111, Loss G: -0.0325,Loss D: -0.0289\n",
            "Epoch 112, Loss G: -0.0575,Loss D: -0.0171\n",
            "Epoch 113, Loss G: -0.0500,Loss D:  0.0096\n",
            "Epoch 114, Loss G: -0.0900,Loss D:  0.0314\n",
            "Epoch 115, Loss G: -0.1152,Loss D:  0.0621\n",
            "Epoch 116, Loss G: -0.1133,Loss D:  0.0690\n",
            "Epoch 117, Loss G: -0.1291,Loss D:  0.0935\n",
            "Epoch 118, Loss G: -0.1310,Loss D:  0.1208\n",
            "Epoch 119, Loss G: -0.1303,Loss D:  0.1259\n",
            "Epoch 120, Loss G: -0.1257,Loss D:  0.1339\n",
            "Epoch 121, Loss G: -0.1322,Loss D:  0.1039\n",
            "Epoch 122, Loss G: -0.1056,Loss D:  0.1124\n",
            "Epoch 123, Loss G: -0.0812,Loss D:  0.0739\n",
            "Epoch 124, Loss G: -0.0628,Loss D:  0.0516\n",
            "Epoch 125, Loss G: -0.0323,Loss D:  0.0066\n",
            "Epoch 126, Loss G:  0.0097,Loss D: -0.0051\n",
            "Epoch 127, Loss G:  0.0323,Loss D: -0.0326\n",
            "Epoch 128, Loss G:  0.0577,Loss D: -0.0866\n",
            "Epoch 129, Loss G:  0.0938,Loss D: -0.0851\n",
            "Epoch 130, Loss G:  0.1149,Loss D: -0.1210\n",
            "Epoch 131, Loss G:  0.1186,Loss D: -0.1530\n",
            "Epoch 132, Loss G:  0.1316,Loss D: -0.1436\n",
            "Epoch 133, Loss G:  0.1494,Loss D: -0.1827\n",
            "Epoch 134, Loss G:  0.1213,Loss D: -0.1900\n",
            "Epoch 135, Loss G:  0.0994,Loss D: -0.1740\n",
            "Epoch 136, Loss G:  0.1106,Loss D: -0.1673\n",
            "Epoch 137, Loss G:  0.0656,Loss D: -0.1138\n",
            "Epoch 138, Loss G:  0.0386,Loss D: -0.1143\n",
            "Epoch 139, Loss G: -0.0053,Loss D: -0.0783\n",
            "Epoch 140, Loss G: -0.0177,Loss D: -0.0114\n",
            "Epoch 141, Loss G: -0.0417,Loss D: -0.0096\n",
            "Epoch 142, Loss G: -0.0459,Loss D:  0.0208\n",
            "Epoch 143, Loss G: -0.0816,Loss D:  0.0282\n",
            "Epoch 144, Loss G: -0.1003,Loss D:  0.0576\n",
            "Epoch 145, Loss G: -0.1030,Loss D:  0.0820\n",
            "Epoch 146, Loss G: -0.1173,Loss D:  0.0654\n",
            "Epoch 147, Loss G: -0.0878,Loss D:  0.0602\n",
            "Epoch 148, Loss G: -0.0977,Loss D:  0.0583\n",
            "Epoch 149, Loss G: -0.0583,Loss D:  0.0746\n",
            "Epoch 150, Loss G: -0.0656,Loss D:  0.0574\n",
            "Epoch 151, Loss G: -0.0518,Loss D:  0.0471\n",
            "Epoch 152, Loss G: -0.0522,Loss D:  0.0569\n",
            "Epoch 153, Loss G: -0.0199,Loss D:  0.0099\n",
            "Epoch 154, Loss G: -0.0318,Loss D: -0.0039\n",
            "Epoch 155, Loss G: -0.0289,Loss D:  0.0283\n",
            "Epoch 156, Loss G: -0.0405,Loss D: -0.0041\n",
            "Epoch 157, Loss G: -0.0617,Loss D:  0.0379\n",
            "Epoch 158, Loss G: -0.0713,Loss D:  0.0398\n",
            "Epoch 159, Loss G: -0.0798,Loss D:  0.0344\n",
            "Epoch 160, Loss G: -0.0913,Loss D:  0.0353\n",
            "Epoch 161, Loss G: -0.1167,Loss D:  0.0316\n",
            "Epoch 162, Loss G: -0.1444,Loss D:  0.0556\n",
            "Epoch 163, Loss G: -0.1404,Loss D:  0.0608\n",
            "Epoch 164, Loss G: -0.1550,Loss D:  0.0183\n",
            "Epoch 165, Loss G: -0.1663,Loss D:  0.0595\n",
            "Epoch 166, Loss G: -0.1428,Loss D:  0.0467\n",
            "Epoch 167, Loss G: -0.1435,Loss D:  0.0328\n",
            "Epoch 168, Loss G: -0.1350,Loss D:  0.0188\n",
            "Epoch 169, Loss G: -0.1208,Loss D: -0.0450\n",
            "Epoch 170, Loss G: -0.1280,Loss D: -0.0240\n",
            "Epoch 171, Loss G: -0.0912,Loss D: -0.0517\n",
            "Epoch 172, Loss G: -0.0991,Loss D: -0.0891\n",
            "Epoch 173, Loss G: -0.0947,Loss D: -0.0512\n",
            "Epoch 174, Loss G: -0.0969,Loss D: -0.0956\n",
            "Epoch 175, Loss G: -0.1005,Loss D: -0.1011\n",
            "Epoch 176, Loss G: -0.1108,Loss D: -0.1360\n",
            "Epoch 177, Loss G: -0.1586,Loss D: -0.1111\n",
            "Epoch 178, Loss G: -0.1366,Loss D: -0.0578\n",
            "Epoch 179, Loss G: -0.1780,Loss D: -0.0547\n",
            "Epoch 180, Loss G: -0.1981,Loss D: -0.0613\n",
            "Epoch 181, Loss G: -0.2032,Loss D: -0.0214\n",
            "Epoch 182, Loss G: -0.2367,Loss D:  0.0163\n",
            "Epoch 183, Loss G: -0.2478,Loss D:  0.0204\n",
            "Epoch 184, Loss G: -0.2627,Loss D:  0.0542\n",
            "Epoch 185, Loss G: -0.2782,Loss D:  0.0441\n",
            "Epoch 186, Loss G: -0.2924,Loss D:  0.0533\n",
            "Epoch 187, Loss G: -0.2910,Loss D:  0.0715\n",
            "Epoch 188, Loss G: -0.2918,Loss D:  0.0569\n",
            "Epoch 189, Loss G: -0.2603,Loss D:  0.0419\n",
            "Epoch 190, Loss G: -0.2511,Loss D:  0.0011\n",
            "Epoch 191, Loss G: -0.2112,Loss D:  0.0481\n",
            "Epoch 192, Loss G: -0.2072,Loss D:  0.0401\n",
            "Epoch 193, Loss G: -0.1984,Loss D:  0.0036\n",
            "Epoch 194, Loss G: -0.1545,Loss D: -0.0035\n",
            "Epoch 195, Loss G: -0.1641,Loss D: -0.0158\n",
            "Epoch 196, Loss G: -0.1562,Loss D:  0.0007\n",
            "Epoch 197, Loss G: -0.1702,Loss D: -0.0149\n",
            "Epoch 198, Loss G: -0.1913,Loss D:  0.0311\n",
            "Epoch 199, Loss G: -0.1999,Loss D:  0.0011\n",
            "Epoch 200, Loss G: -0.1955,Loss D:  0.0180\n",
            "Epoch 201, Loss G: -0.1945,Loss D:  0.0388\n",
            "Epoch 202, Loss G: -0.2044,Loss D:  0.0505\n",
            "Epoch 203, Loss G: -0.1948,Loss D:  0.0454\n",
            "Epoch 204, Loss G: -0.1873,Loss D:  0.0602\n",
            "Epoch 205, Loss G: -0.1920,Loss D:  0.0347\n",
            "Epoch 206, Loss G: -0.1553,Loss D:  0.0456\n",
            "Epoch 207, Loss G: -0.1577,Loss D:  0.0291\n",
            "Epoch 208, Loss G: -0.1407,Loss D:  0.0053\n",
            "Epoch 209, Loss G: -0.1038,Loss D: -0.0217\n",
            "Epoch 210, Loss G: -0.0875,Loss D:  0.0117\n",
            "Epoch 211, Loss G: -0.0550,Loss D: -0.0623\n",
            "Epoch 212, Loss G: -0.0591,Loss D: -0.1108\n",
            "Epoch 213, Loss G: -0.0670,Loss D: -0.0998\n",
            "Epoch 214, Loss G: -0.0632,Loss D: -0.0591\n",
            "Epoch 215, Loss G: -0.0438,Loss D: -0.0591\n",
            "Epoch 216, Loss G: -0.0820,Loss D: -0.0609\n",
            "Epoch 217, Loss G: -0.0890,Loss D: -0.0710\n",
            "Epoch 218, Loss G: -0.0941,Loss D: -0.0519\n",
            "Epoch 219, Loss G: -0.1309,Loss D: -0.0117\n",
            "Epoch 220, Loss G: -0.1178,Loss D: -0.0028\n",
            "Epoch 221, Loss G: -0.1062,Loss D:  0.0076\n",
            "Epoch 222, Loss G: -0.1272,Loss D: -0.0128\n",
            "Epoch 223, Loss G: -0.1030,Loss D:  0.0209\n",
            "Epoch 224, Loss G: -0.0892,Loss D:  0.0196\n",
            "Epoch 225, Loss G: -0.0776,Loss D:  0.0204\n",
            "Epoch 226, Loss G: -0.0633,Loss D: -0.0155\n",
            "Epoch 227, Loss G: -0.0520,Loss D: -0.0237\n",
            "Epoch 228, Loss G: -0.0350,Loss D: -0.0195\n",
            "Epoch 229, Loss G: -0.0443,Loss D: -0.0339\n",
            "Epoch 230, Loss G: -0.0540,Loss D: -0.0041\n",
            "Epoch 231, Loss G: -0.0781,Loss D: -0.0314\n",
            "Epoch 232, Loss G: -0.0811,Loss D:  0.0033\n",
            "Epoch 233, Loss G: -0.0892,Loss D:  0.0142\n",
            "Epoch 234, Loss G: -0.1114,Loss D:  0.0091\n",
            "Epoch 235, Loss G: -0.1325,Loss D:  0.0380\n",
            "Epoch 236, Loss G: -0.1534,Loss D:  0.0729\n",
            "Epoch 237, Loss G: -0.1495,Loss D:  0.0326\n",
            "Epoch 238, Loss G: -0.1554,Loss D:  0.0304\n",
            "Epoch 239, Loss G: -0.1616,Loss D:  0.0250\n",
            "Epoch 240, Loss G: -0.1539,Loss D:  0.0006\n",
            "Epoch 241, Loss G: -0.1236,Loss D: -0.0034\n",
            "Epoch 242, Loss G: -0.1410,Loss D: -0.0064\n",
            "Epoch 243, Loss G: -0.1103,Loss D: -0.0630\n",
            "Epoch 244, Loss G: -0.1056,Loss D: -0.0794\n",
            "Epoch 245, Loss G: -0.1312,Loss D: -0.0930\n",
            "Epoch 246, Loss G: -0.1206,Loss D: -0.0898\n",
            "Epoch 247, Loss G: -0.1362,Loss D: -0.0750\n",
            "Epoch 248, Loss G: -0.1424,Loss D: -0.0453\n",
            "Epoch 249, Loss G: -0.2207,Loss D: -0.0445\n",
            "Epoch 250, Loss G: -0.1893,Loss D: -0.0216\n",
            "Epoch 251, Loss G: -0.2202,Loss D: -0.0307\n",
            "Epoch 252, Loss G: -0.2283,Loss D: -0.0245\n",
            "Epoch 253, Loss G: -0.2453,Loss D: -0.0112\n",
            "Epoch 254, Loss G: -0.2723,Loss D: -0.0138\n",
            "Epoch 255, Loss G: -0.2582,Loss D: -0.0005\n",
            "Epoch 256, Loss G: -0.2598,Loss D: -0.0164\n",
            "Epoch 257, Loss G: -0.2227,Loss D: -0.0205\n",
            "Epoch 258, Loss G: -0.2445,Loss D: -0.0153\n",
            "Epoch 259, Loss G: -0.2223,Loss D:  0.0007\n",
            "Epoch 260, Loss G: -0.2288,Loss D: -0.0047\n",
            "Epoch 261, Loss G: -0.2154,Loss D:  0.0149\n",
            "Epoch 262, Loss G: -0.2505,Loss D:  0.0299\n",
            "Epoch 263, Loss G: -0.2421,Loss D:  0.0320\n",
            "Epoch 264, Loss G: -0.2346,Loss D:  0.0410\n",
            "Epoch 265, Loss G: -0.2216,Loss D:  0.0273\n",
            "Epoch 266, Loss G: -0.2131,Loss D:  0.0294\n",
            "Epoch 267, Loss G: -0.2273,Loss D:  0.0287\n",
            "Epoch 268, Loss G: -0.1923,Loss D:  0.0043\n",
            "Epoch 269, Loss G: -0.1749,Loss D: -0.0076\n",
            "Epoch 270, Loss G: -0.1664,Loss D: -0.0332\n",
            "Epoch 271, Loss G: -0.1337,Loss D: -0.0133\n",
            "Epoch 272, Loss G: -0.1045,Loss D: -0.0394\n",
            "Epoch 273, Loss G: -0.1262,Loss D: -0.0160\n",
            "Epoch 274, Loss G: -0.1187,Loss D: -0.0371\n",
            "Epoch 275, Loss G: -0.1220,Loss D: -0.0304\n",
            "Epoch 276, Loss G: -0.1233,Loss D: -0.0173\n",
            "Epoch 277, Loss G: -0.1037,Loss D: -0.0165\n",
            "Epoch 278, Loss G: -0.0699,Loss D:  0.0104\n",
            "Epoch 279, Loss G: -0.0868,Loss D: -0.0474\n",
            "Epoch 280, Loss G: -0.0600,Loss D: -0.0637\n",
            "Epoch 281, Loss G: -0.0522,Loss D: -0.0367\n",
            "Epoch 282, Loss G: -0.0387,Loss D: -0.0799\n",
            "Epoch 283, Loss G: -0.0411,Loss D: -0.0864\n",
            "Epoch 284, Loss G: -0.0535,Loss D: -0.0624\n",
            "Epoch 285, Loss G: -0.0638,Loss D: -0.0361\n",
            "Epoch 286, Loss G: -0.0719,Loss D: -0.0095\n",
            "Epoch 287, Loss G: -0.0811,Loss D: -0.0319\n",
            "Epoch 288, Loss G: -0.0716,Loss D: -0.0440\n",
            "Epoch 289, Loss G: -0.0748,Loss D: -0.0095\n",
            "Epoch 290, Loss G: -0.0955,Loss D: -0.0245\n",
            "Epoch 291, Loss G: -0.0831,Loss D:  0.0029\n",
            "Epoch 292, Loss G: -0.1012,Loss D:  0.0013\n",
            "Epoch 293, Loss G: -0.1127,Loss D:  0.0083\n",
            "Epoch 294, Loss G: -0.1570,Loss D:  0.0105\n",
            "Epoch 295, Loss G: -0.1464,Loss D:  0.0138\n",
            "Epoch 296, Loss G: -0.1495,Loss D:  0.0065\n",
            "Epoch 297, Loss G: -0.1647,Loss D:  0.0413\n",
            "Epoch 298, Loss G: -0.1667,Loss D:  0.0632\n",
            "Epoch 299, Loss G: -0.1741,Loss D:  0.0215\n",
            "Epoch 300, Loss G: -0.1446,Loss D:  0.0128\n"
          ]
        }
      ],
      "source": [
        "# np.random.seed(42)\n",
        "\n",
        "# parameter available \n",
        "\n",
        "sim_n = int(np.ceil(samp_size_bin_ci(alpha=0.05, proportion=0.2, width=0.1)))\n",
        "n =1000\n",
        "k = 100 \n",
        "p = k/n\n",
        "\n",
        "# Parameters of binomal parent distribution\n",
        "\n",
        "k = 100 \n",
        "n_size = 1000\n",
        "\n",
        "## Simulate data as input to GAN\n",
        "x = np.random.binomial(n= n, p = p, size = n_size)\n",
        "\n",
        "## Convert numpy vector to pandas Series and plot the histogram/density\n",
        "# pd.Series(x).hist(bins=100)\n",
        "\n",
        "## Convert vector to pandas dataFrame\n",
        "x_pd = pd.DataFrame({\"x\": x})\n",
        "# x_pd\n",
        "\n",
        "\n",
        "## Feed the simulated data into SDV and sample synthetic data from the fitted GAN\n",
        "## Instantiate an SDV class object\n",
        "model = CTGAN(\n",
        "    epochs=300,\n",
        "    cuda=True,\n",
        "    batch_size=10_000,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "## Fit a GAN to the simulated data from above\n",
        "t0 = time()\n",
        "model.fit(x_pd)\n",
        "t1 = time()\n",
        "runtime = t1-t0\n",
        "\n",
        "def sim_gan_data2(n, p, k, sim_n, model):\n",
        "    ## Sample synthetic data from the trained GAN\n",
        "    sampled = model.sample(num_rows=sim_n)\n",
        "    \n",
        "    return(sampled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_ci_samp_size_gan2(n,p, k, sim_n, model):\n",
        "    ## Generate random data\n",
        "\n",
        "    x = sim_gan_data2(n=n, \n",
        "                      p=p, \n",
        "                      k=k, \n",
        "                      sim_n=sim_n, \n",
        "                      model=model)\n",
        "    \n",
        "    ## Analyze generated/simulated data\n",
        "    res = scipy.stats.binomtest(k=k, n =n, p=p, alternative='two-sided')\n",
        "    \n",
        "    \n",
        "    ## Extract the estimate and CI\n",
        "    p_ll, p_ul = res.proportion_ci(confidence_level=0.95)\n",
        "    p_hat = np.mean(x)\n",
        "    \n",
        "    # Return the estimate and the CI to the user\n",
        "    # [] make it a list instead of scalar\n",
        "    out = pd.DataFrame({'mean': [p_hat],\n",
        "                        'll95_mean': [p_ll],\n",
        "                        'ul95_mean': [p_ul]})\n",
        "    \n",
        "    return(out)\n",
        "\n"
      ],
      "metadata": {
        "id": "d3YHJ6TfxnMC"
      },
      "id": "d3YHJ6TfxnMC",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Replicate above function number of simulation replicate times\n",
        "\n",
        "# parameter available \n",
        "sim_n = int(np.ceil(samp_size_bin_ci(alpha=0.05, proportion=0.2, width=0.1)))\n",
        "n =1000\n",
        "k = 100 \n",
        "p = k/n\n",
        "n_size = 1000\n",
        "\n",
        "\n",
        "\n",
        "## Number simulation replicates\n",
        "n_rep = 2000\n",
        "\n",
        "## Simulate n_rep copies of sample size trials\n",
        "sim_out = []\n",
        "\n",
        "#Record start time\n",
        "t0 = time()\n",
        "\n",
        "## Loop over number simulation replicates, storing results in list\n",
        "for i in trange(0, n_rep):\n",
        "    sim_out.append(bin_ci_samp_size_gan2(n=n,p=p, k=k, sim_n=sim_n, model=model))\n",
        "    \n",
        "\n",
        "#Record end time\n",
        "t1 = time()\n",
        "\n",
        "#Calculate runtime\n",
        "runtime = t1 - t0\n",
        "print(f'runtime is {runtime}')\n",
        "\n",
        "### Aggregate results into dataframe\n",
        "sim_df = pd.concat(sim_out)\n",
        "\n",
        "#Calculate means of each column in the array #axis means column mean \n",
        "sim_means = np.mean(sim_df, axis=0)\n",
        "print(f'sim_means is {sim_means} +/- {np.std(sim_df, axis=0)}')\n",
        "\n",
        "#Calculate the width of the confidence interval\n",
        "ci_width = sim_means[2] - sim_means[1]\n",
        "print(f'ci_width is {ci_width}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "001e89fdf7984c36a8dcf65c78513d06",
            "3dbb182889cd409b8d2663314c41cd00",
            "ab5b7a34520440ab832cf485141a9c2b",
            "5fceba5df04846ce87cecbcc0674b06a",
            "93cbf6dfcd5c48af842e8183bfd938ee",
            "20734aec4210497fbd02f49cc2ebbeaa",
            "3fba980d86bf498facbbaa2602120004",
            "e1feddbf851e467c84b298d5d110e2c3",
            "4a23b30f04bb473b942b91dae670170d",
            "c64b2dafdf384f1bbb4606b703ec85a1",
            "d612843b3b3b474a96f13de7fde0380e"
          ]
        },
        "id": "SwJj8PelxnSS",
        "outputId": "ea4d4b87-8dff-4ec8-93ff-891a24225419"
      },
      "id": "SwJj8PelxnSS",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "001e89fdf7984c36a8dcf65c78513d06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "runtime is 80.92124938964844\n",
            "sim_means is mean         96.641205\n",
            "ll95_mean     0.082105\n",
            "ul95_mean     0.120288\n",
            "dtype: float64 +/- mean         7.619357e-01\n",
            "ll95_mean    1.387779e-17\n",
            "ul95_mean    0.000000e+00\n",
            "dtype: float64\n",
            "ci_width is 0.03818260216311377\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "001e89fdf7984c36a8dcf65c78513d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dbb182889cd409b8d2663314c41cd00",
              "IPY_MODEL_ab5b7a34520440ab832cf485141a9c2b",
              "IPY_MODEL_5fceba5df04846ce87cecbcc0674b06a"
            ],
            "layout": "IPY_MODEL_93cbf6dfcd5c48af842e8183bfd938ee"
          }
        },
        "3dbb182889cd409b8d2663314c41cd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20734aec4210497fbd02f49cc2ebbeaa",
            "placeholder": "​",
            "style": "IPY_MODEL_3fba980d86bf498facbbaa2602120004",
            "value": "100%"
          }
        },
        "ab5b7a34520440ab832cf485141a9c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1feddbf851e467c84b298d5d110e2c3",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a23b30f04bb473b942b91dae670170d",
            "value": 2000
          }
        },
        "5fceba5df04846ce87cecbcc0674b06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c64b2dafdf384f1bbb4606b703ec85a1",
            "placeholder": "​",
            "style": "IPY_MODEL_d612843b3b3b474a96f13de7fde0380e",
            "value": " 2000/2000 [01:20&lt;00:00, 31.28it/s]"
          }
        },
        "93cbf6dfcd5c48af842e8183bfd938ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20734aec4210497fbd02f49cc2ebbeaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fba980d86bf498facbbaa2602120004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1feddbf851e467c84b298d5d110e2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a23b30f04bb473b942b91dae670170d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c64b2dafdf384f1bbb4606b703ec85a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d612843b3b3b474a96f13de7fde0380e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}